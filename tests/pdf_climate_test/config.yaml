# DELM Configuration Example
# This file shows all available configuration options for DELM

# LLM extraction configuration
llm_extraction:
  provider: "openai"                  # LLM provider (openai, anthropic, google, groq, together, fireworks)
  name: "gpt-4o-mini"                 # LLM model name
  temperature: 0.0                    # Temperature for generation (0.0-2.0)
  max_retries: 3                      # Maximum API retries
  batch_size: 10                      # Batch size for processing
  max_workers: 1                      # Number of concurrent workers
  base_delay: 1.0                     # Base delay for retry handler (seconds)
  dotenv_path: ".env"                 # Path to .env file (optional, can be null)
  track_cost: true                    # Whether to track cost of API calls

semantic_cache:
  backend: "sqlite"        # sqlite | lmdb | filesystem

# Schema configuration
schema:
  spec_path: "tests/pdf_climate_test/schema_spec.yaml" # Path to schema specification file
  container_name: "data"        # Container name for nested schemas
  prompt_template: |
    You are a climate change expert who expects meticulous and reliable results.

    Extract the following information from the text:

    {variables}

    Text to analyze:
    {text}

  # Example of a simpler prompt template:
  # prompt_template: |
  #   You are a financial data extraction expert. Extract the following information:
  #   
  #   {variables}
  #   
  #   Text to analyze:
  #   {text}
  #   
  #   Focus on extracting accurate financial data and return results in the specified format.
